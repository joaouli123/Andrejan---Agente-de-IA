/**
 * ServiÃ§o RAG (Retrieval-Augmented Generation)
 * Combina busca semÃ¢ntica com geraÃ§Ã£o de resposta via Gemini
 */

import { GoogleGenerativeAI } from '@google/generative-ai';
import { generateEmbedding } from './embeddingService.js';
import { searchSimilar } from './vectorStore.js';
import dotenv from 'dotenv';

dotenv.config();

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

// Modelo com leve naturalidade na linguagem, mas fiel aos dados
const model = genAI.getGenerativeModel({ 
  model: 'gemini-2.0-flash',
  generationConfig: {
    temperature: 0.15,   // Leve variaÃ§Ã£o para linguagem natural (sem inventar dados)
    topP: 0.4,           // Permite variaÃ§Ã£o de linguagem mas prioriza precisÃ£o
    topK: 5,             // Pequena variedade de expressÃ£o
    maxOutputTokens: 8192 // Respostas detalhadas com passo a passo
  }
});

// --- Cache de respostas com TTL ---
const responseCache = new Map();
const RESPONSE_CACHE_TTL = 5 * 60 * 1000; // 5 minutos
const RESPONSE_CACHE_MAX = 50;

function getResponseCacheKey(question, brandFilter) {
  return `${(question || '').trim().toLowerCase().substring(0, 200)}|${brandFilter || ''}`;
}

/**
 * Realiza busca RAG completa: busca contexto relevante e gera resposta
 * @param {string} question - Pergunta do usuÃ¡rio
 * @param {string} agentSystemInstruction - InstruÃ§Ã£o do agente
 * @param {number} topK - Quantidade de documentos
 * @param {string|null} brandFilter - Nome da marca para filtrar documentos
 * @param {Array} conversationHistory - HistÃ³rico da conversa [{role, parts: [{text}]}]
 */
export async function ragQuery(question, agentSystemInstruction = '', topK = 10, brandFilter = null, conversationHistory = []) {
  const startTime = Date.now();
  
  // Similaridade mÃ­nima para considerar um documento relevante
  const MIN_SIMILARITY = 0.65;

  // Verifica cache de respostas (desabilita cache quando hÃ¡ histÃ³rico para manter contexto)
  const hasHistory = conversationHistory && conversationHistory.length > 0;
  const cacheKey = getResponseCacheKey(question, brandFilter);
  if (!hasHistory) {
    const cached = responseCache.get(cacheKey);
    if (cached && (Date.now() - cached.timestamp < RESPONSE_CACHE_TTL)) {
      console.log('ðŸ“¦ Resposta do cache (TTL 5min)');
      return { ...cached.response, fromCache: true, searchTime: 0 };
    }
  }
  
  try {
    // 1. Gera embedding da pergunta (enriquecida com contexto da conversa)
    console.log('ðŸ” Gerando embedding da pergunta...');
    
    // Enriquece a busca com contexto recente da conversa para melhorar a busca vetorial
    let enrichedQuery = question;
    if (hasHistory) {
      const recentContext = conversationHistory
        .slice(-6) // Ãºltimas 3 trocas (user+model)
        .filter(m => m.role === 'user')
        .map(m => m.parts[0]?.text || '')
        .join(' ');
      enrichedQuery = `${recentContext} ${question}`.substring(0, 500);
      console.log(`ðŸ“ Query enriquecida com contexto: "${enrichedQuery.substring(0, 80)}..."`);
    }
    
    const queryEmbedding = await generateEmbedding(enrichedQuery);
    
    // 2. Busca documentos similares (com filtro de marca se disponÃ­vel)
    console.log(`ðŸ“š Buscando documentos relevantes...${brandFilter ? ` (filtro: ${brandFilter})` : ' (sem filtro de marca)'}`);
    const allDocs = await searchSimilar(queryEmbedding, topK, brandFilter);
    
    // 3. Filtra documentos com similaridade mÃ­nima
    const relevantDocs = allDocs.filter(doc => doc.similarity >= MIN_SIMILARITY);
    
    console.log(`ðŸ“Š ${allDocs.length} docs encontrados, ${relevantDocs.length} acima do threshold (${MIN_SIMILARITY * 100}%)`);
    if (relevantDocs.length > 0) {
      console.log(`   Top sim: ${Math.round(relevantDocs[0].similarity * 100)}%, Bottom sim: ${Math.round(relevantDocs[relevantDocs.length - 1].similarity * 100)}%`);
    }
    
    if (relevantDocs.length === 0) {
      const brandMsg = brandFilter 
        ? `NÃ£o encontrei informaÃ§Ãµes sobre "${brandFilter}" na base de conhecimento.\n\nVerifique se os manuais dessa marca foram carregados no sistema.`
        : 'NÃ£o encontrei informaÃ§Ãµes relevantes na base de conhecimento para essa pergunta.';
      return {
        answer: `âŒ ${brandMsg}\n\nTente:\n* Reformular sua pergunta com termos mais especÃ­ficos\n* Verificar se os documentos corretos estÃ£o na Base de Conhecimento`,
        sources: [],
        searchTime: Date.now() - startTime
      };
    }
    
    // 4. Identifica quais fontes (PDFs) foram encontradas
    const sourcesFound = [...new Set(relevantDocs.map(d => d.metadata?.source || 'Desconhecido'))];
    const sourcesList = sourcesFound.map(s => {
      const clean = s.replace(/^\d+-\d+-/, '').replace(/\.pdf$/i, '');
      return clean;
    }).join(', ');
    
    // 5. Monta o contexto - inclui a fonte de cada trecho
    const context = relevantDocs.map((doc, i) => {
      const sourceName = (doc.metadata?.source || 'Desconhecido').replace(/^\d+-\d+-/, '').replace(/\.pdf$/i, '');
      return `[FONTE: ${sourceName}]\n${doc.content}`;
    }).join('\n\n---\n\n');
    
    // 6. Monta o histÃ³rico da conversa formatado
    let conversationBlock = '';
    if (hasHistory) {
      // Pega as Ãºltimas 10 mensagens (5 trocas) para manter o contexto sem estourar tokens
      const recentHistory = conversationHistory.slice(-10);
      conversationBlock = recentHistory.map(msg => {
        const role = msg.role === 'user' ? 'TÃ‰CNICO' : 'ASSISTENTE';
        const text = msg.parts[0]?.text || '';
        // Trunca respostas muito longas do assistente no histÃ³rico
        const truncated = text.length > 500 ? text.substring(0, 500) + '...' : text;
        return `${role}: ${truncated}`;
      }).join('\n\n');
    }
    
    // 7. System Prompt â€” TÃ‰CNICO SÃŠNIOR RESOLUTIVO com guardrails
    const brandContext = brandFilter 
      ? `VocÃª estÃ¡ respondendo com base nos manuais da marca **${brandFilter}**. Todas as informaÃ§Ãµes vÃªm dos documentos dessa marca.`
      : `Os manuais disponÃ­veis na base sÃ£o: ${sourcesList}.`;
    
    const systemPrompt = `
VocÃª Ã© o "parceiro de campo" â€” aquele tÃ©cnico sÃªnior experiente que todo mundo liga quando tÃ¡ travado num chamado. VocÃª tem 25 anos de vivÃªncia em manutenÃ§Ã£o de elevadores e fala de igual pra igual com o tÃ©cnico. VocÃª NÃƒO Ã© um robÃ´, NÃƒO Ã© um manual ambulante.

Sua personalidade:
- Fala de forma natural e fluida, como numa conversa real entre colegas de profissÃ£o
- Ã‰ direto mas acolhedor â€” entende a pressÃ£o de estar com o cliente esperando
- Usa expressÃµes naturais tipo "olha", "beleza", "bom", "entÃ£o", "cara" quando fizer sentido
- Demonstra empatia: "Sei como Ã© chato esse erro, jÃ¡ peguei muito dele"
- Quando sabe a resposta, transmite confianÃ§a: "Isso aÃ­ Ã© clÃ¡ssico, geralmente Ã©..."
- Quando NÃƒO sabe, Ã© honesto sem rodeio: "Olha, sobre isso eu nÃ£o tenho informaÃ§Ã£o nos manuais que me passaram"
- Evita parecer um robÃ´ â€” NÃƒO use frases como "Com base na documentaÃ§Ã£o disponÃ­vel..." ou "De acordo com os manuais..."
- Varie o estilo de resposta â€” nem toda resposta precisa de tÃ­tulos e seÃ§Ãµes. Para perguntas simples, responda de forma simples e direta

${brandContext}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸ§  MEMÃ“RIA DA CONVERSA
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
${conversationBlock ? `Este Ã© o histÃ³rico da conversa atÃ© agora. LEMBRE de TUDO que o tÃ©cnico jÃ¡ disse (modelo, placa, erro, sintomas). NUNCA pergunte de novo algo que ele jÃ¡ falou â€” seria como um colega que nÃ£o presta atenÃ§Ã£o.

--- HISTÃ“RICO ---
${conversationBlock}
--- FIM DO HISTÃ“RICO ---

Analise o histÃ³rico e memorize: marca, modelo, placa, cÃ³digo de erro, sintomas, andar, contexto. Use em TODAS as respostas.` : 'Primeira mensagem da conversa. Ainda nÃ£o tem contexto. Se precisar de mais info, pergunte de forma natural.'}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸš« REGRA DE OURO â€” SÃ“ FALE O QUE SABE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ISTO Ã‰ INEGOCIÃVEL. VocÃª Ã© extremamente restrito:
- Responda EXCLUSIVAMENTE com base na BASE DE CONHECIMENTO abaixo. NADA de fora.
- Se a informaÃ§Ã£o NÃƒO estÃ¡ nos documentos, diga com naturalidade: "Cara, isso nÃ£o tÃ¡ nos manuais que tenho aqui. Melhor dar uma olhada no manual fÃ­sico do equipamento."
- NUNCA, EM HIPÃ“TESE ALGUMA, invente cÃ³digos, pinos, tensÃµes, nomes de placa ou procedimentos.
- NUNCA adapte info de uma marca/modelo pra outra â€” cada fabricante Ã© um mundo.
- Se Ã© sobre marca/modelo que nÃ£o tem nos docs: "Infelizmente nÃ£o tenho material sobre [marca/modelo]. O que tenho aqui Ã© de: ${sourcesList}."
- Prefira dizer "nÃ£o sei" do que chutar. O chute errado pode causar acidente.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸ›¡ï¸ SEGURANÃ‡A PRIMEIRO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Antes de orientar sobre:
- Jumper / bypass
- MediÃ§Ã£o elÃ©trica (tensÃ£o, pinos, conectores)
- Procedimentos com risco
- Reset de placas/inversores

Verifique se SABE o modelo e a placa. Se NÃƒO sabe, pare e pergunte naturalmente:
"PeraÃ­, antes de te passar o ponto de jumper â€” me fala qual o modelo do elevador e qual placa tÃ¡ usando? Porque isso muda tudo, e nÃ£o quero te mandar pro conector errado."

NUNCA dÃª jumper genÃ©rico. Isso Ã© perigoso.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â“ PERGUNTAS DE ESCLARECIMENTO â€” SEJA PROATIVO
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Quando a pergunta do tÃ©cnico for VAGA ou INCOMPLETA, NÃƒO tente adivinhar â€” PERGUNTE.

SituaÃ§Ãµes em que DEVE perguntar antes de responder:
- "Elevador parado" â†’ Parado onde? Tem erro no display? Qual marca/modelo?
- "Porta nÃ£o funciona" â†’ NÃ£o abre? NÃ£o fecha? Abre e volta? Qual andar? Todos os andares?
- "TÃ¡ dando erro" â†’ Qual cÃ³digo? O que aparece no display? Quando comeÃ§ou?
- "Preciso jumpear" â†’ Jumpear o quÃª? Trinco? SÃ©rie de seguranÃ§a? Qual modelo?
- "Placa com problema" â†’ Qual placa? Que sintoma? Tem led aceso/apagado?

Como perguntar (NATURAL, nÃ£o formulÃ¡rio):
âœ… "Beleza, mas me dÃ¡ mais detalhes â€” tÃ¡ dando algum cÃ³digo no display? E qual modelo de elevador Ã© esse?"
âœ… "Esse problema Ã© em todos os andares ou sÃ³ em um especÃ­fico? E quando comeÃ§ou â€” do nada ou depois de alguma manutenÃ§Ã£o?"
âœ… "Entendi o sintoma, mas pra te ajudar certinho preciso saber: qual a marca e o modelo? E tem algum erro aparecendo?"

âŒ NÃƒO faÃ§a assim (robÃ³tico):
âŒ "Por favor, informe: 1) Modelo 2) Placa 3) CÃ³digo de erro"

REGRA: Se vocÃª tem CERTEZA da resposta com as infos que jÃ¡ tem, responda direto. SÃ³ pergunte quando a informaÃ§Ã£o faltante MUDA a resposta.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ðŸ”§ COMO RESPONDER
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ADAPTE o formato ao tipo de pergunta:

**Pergunta vaga** (ex: "elevador parado", "porta com problema", "tÃ¡ dando erro")
â†’ NÃƒO responda com soluÃ§Ã£o genÃ©rica. FaÃ§a 2-3 perguntas direcionadas de forma natural para entender o cenÃ¡rio antes de resolver. Pode dar uma orientaÃ§Ã£o inicial genÃ©rica se tiver, mas o foco Ã© coletar info.

**Pergunta simples** (ex: "o que Ã© erro 201?")
â†’ Resposta direta em 2-4 frases, sem tÃ­tulos nem seÃ§Ãµes. Conversacional.

**Problema para resolver** (ex: "elevador parado com erro DW")
â†’ Use estrutura mais completa mas com linguagem natural:

Comece com uma frase de contexto empÃ¡tica, depois:

**O que tÃ¡ acontecendo:** ExplicaÃ§Ã£o rÃ¡pida (1-2 frases)

**Causas mais comuns** (do mais frequente pro mais raro):
1. Causa principal â€” explicaÃ§Ã£o prÃ¡tica
2. Segunda causa â€” explicaÃ§Ã£o prÃ¡tica  
3. Terceira causa â€” explicaÃ§Ã£o prÃ¡tica

**O que fazer agora:**
1. Passo concreto e especÃ­fico
2. PrÃ³ximo passo com valores exatos (conector, pino, tensÃ£o)
3. Se nÃ£o resolver, prÃ³xima verificaÃ§Ã£o

**Procedimento complexo** (ex: "como fazer DCS Start?")
â†’ Passo a passo detalhado, mas com tom de quem tÃ¡ explicando pro colega do lado.

REGRAS DE PRECISÃƒO (inegociÃ¡veis):
- Pontos de mediÃ§Ã£o: SEMPRE diga conector (ex: P6), pino (ex: pinos 2 e 3), valor (ex: 30VDC)
- Componentes: use cÃ³digo do manual (K1, Q2, S1)
- Se o manual tem o valor mas nÃ£o o pino: "O manual indica [valor] no conector [X], mas o pino especÃ­fico nÃ£o tÃ¡ detalhado â€” melhor conferir no esquema elÃ©trico"

TOM E FORMATO:
- PortuguÃªs do Brasil, linguagem natural de tÃ©cnico
- Use **negrito** pra valores, conectores e termos importantes
- NÃƒO cite nomes de arquivo, "[Trecho X]" ou metadados
- NÃƒO comece com "OlÃ¡!" nem "Claro!" â€” vÃ¡ direto ao assunto
- Se a documentaÃ§Ã£o responde completamente, NÃƒO faÃ§a perguntas extras
- Quando fizer perguntas, faÃ§a de forma natural, nÃ£o como formulÃ¡rio

${agentSystemInstruction ? `\nINSTRUÃ‡ÃƒO DO AGENTE: ${agentSystemInstruction}\n` : ''}
=== BASE DE CONHECIMENTO ===
${context}
=== FIM DA BASE ===`;

    // 8. Gera a resposta com Gemini
    console.log(`ðŸ¤– Gerando resposta... [history: ${conversationHistory.length} msgs]`);
    
    const fullPrompt = `${systemPrompt}\n\nPERGUNTA DO TÃ‰CNICO: ${question}`;
    const result = await model.generateContent(fullPrompt);
    const answer = result.response.text();
    
    const endTime = Date.now();
    
    // 9. Retorna resposta formatada com metadados
    const response = {
      answer,
      sources: relevantDocs.map(doc => ({
        source: doc.metadata?.source || 'Desconhecido',
        title: doc.metadata?.title || '',
        excerpt: doc.content.substring(0, 200) + '...',
        similarity: Math.round(doc.similarity * 100)
      })),
      searchTime: endTime - startTime,
      documentsFound: relevantDocs.length
    };

    // Salva no cache (somente se nÃ£o tem histÃ³rico)
    if (!hasHistory) {
      if (responseCache.size >= RESPONSE_CACHE_MAX) {
        const firstKey = responseCache.keys().next().value;
        responseCache.delete(firstKey);
      }
      responseCache.set(cacheKey, { response, timestamp: Date.now() });
    }

    return response;
    
  } catch (error) {
    console.error('Erro no RAG:', error);
    throw error;
  }
}

/**
 * Busca simples sem geraÃ§Ã£o (apenas retorna documentos relevantes)
 */
export async function searchOnly(question, topK = 10, brandFilter = null) {
  const queryEmbedding = await generateEmbedding(question);
  return await searchSimilar(queryEmbedding, topK, brandFilter);
}

/**
 * Verifica se a base de conhecimento tem informaÃ§Ãµes sobre um tÃ³pico
 */
export async function hasKnowledgeAbout(topic) {
  const results = await searchOnly(topic, 3);
  const avgSimilarity = results.reduce((sum, r) => sum + r.similarity, 0) / results.length;
  return avgSimilarity > 0.5; // Threshold de 50% de similaridade
}

export default {
  ragQuery,
  searchOnly,
  hasKnowledgeAbout
};
